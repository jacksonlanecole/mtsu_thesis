\subsection{Overview}
The primary goal of our work in this project is focused on the
development of a framework that can be used to test general purpose
fitness-functions for comparison of simulated disturbed morphologies with their
real counterparts.
Having a general purpose fitness-function
allows for the generation of preliminary machine scores for all sets of initial
simulation parameters present for each of the 62 Galaxy Zoo: Mergers targets
found at \texttt{https://data.galaxyzoo.org/mergers.html}.
The Galaxy Zoo: Mergers project produced
ranked scores that are indicative of the degree to which the resultant
morphologies of different sets of initial conditions for a merger
correlate with their real counterparts.
These rankings result from the substantial Citizen Science effort comprising
the Galaxy Zoo: Mergers project, and at the completion of the project,
66,395 sets of initial parameters had been scored through review of
over 3 million simulations by volunteers \cite{Holincheck2015}. We make use of
the points in the parameter space that have received a citizen science score.
\begin{clearpage}
\input{./content/figures/project_flowchart.tex}
\end{clearpage}

The primary motivation for having a machine scoring mechanism for these types of
simulations is to reserve human effort for distinguishing the best fitting
morphologies out of the good rendered morphologies. This is in contrast with the
current \textit{modus operandi}, which in some cases results in humans being
tasked with classifying a \textit{clearly} ill-fitting rendered morphology
as \say{bad}. If we can task a computer with making classifications that require
less acute discernment, humans in the
loop can be tasked with finding the \textit{best of the best} rendered
morphologies.

Therefore, we operate under the assumption that an ideal machine scoring
mechanism should be able to essentially recreate the results of the Galaxy Zoo:
Mergers Citizen Science effort nearly exactly.
However, in this work, we focus more on developing a framework to handle
running the simulation software efficiently, storing and organizing the large
volumes of data that are inherent to this project, accessing these data
efficiently, image creation, and image analysis.
In other words, while the ultimate goal for JSPAM is the creation of a general
purpose fitness function to compare the output of the JSPAM simulations to
the real systems it is supposed to model, the fitness function used in our
current working framework is largely a placeholder to ensure
that the framework is working properly score.
We recognize that further work must be done in developing fitness-functions, and
expect that our work will aid further success in doing so.

% ---------------------------------------------------------------------------- %
\subsection{Image Preparation and Target Data Acquisition}
% ---------------------------------------------------------------------------- %
The software we use for target image preparation and for constraining the
initial simulation parameter values is MergerEx, described in
\citet{holincheckThesis} and found at
\texttt{https://github.com/aholinch/MergerEx}. MergerEx greatly simplifies and
speeds up the process of querying various astronomical image servers for
specific sky coordinates, calibrating the images, and estimating initial
parameters that describe the sizes, orientations, and velocities of the
primary and secondary galactic disks in the merger.

Because the data in which we are interested is only the morphology, we can rely
on whichever images display the morphological features most clearly.
The MergerEx software allows us to choose the most appropriate image source from
either the NASA/IPAC Extragalactic Database/STScI Digital Sky Survey (NED/DSS),
or Sloan Digital Sky Survey Data Release 7, 8, or 9 (SDSS DR7, DR8, DR9).
For our purposes, neither the wavelengths comprising the images retrieved nor
the source matter as long as the distribution of luminous stars in the system is
shown in the image \cite{Holincheck2015}. In some cases, \citet{Holincheck2015}
describes that these images can even come from non-scientific data sets as long
as the previously mentioned condition is met.

\citet{Holincheck2015} provides a list of 54 SDSS and 8 Hubble Space Telescope
(HST) targets. For each of these targets, we follow the process for estimation
of the disks as described in Appendix C of \citet{holincheckThesis}.

Rather than leave this task up to users in future work,
a directory containing target images, the initial simulation parameters,
and the full-color press release images has been included in the project
repository, referenced in \ref{sec: appendix}.
% ---------------------------------------------------------------------------- %

% ---------------------------------------------------------------------------- %
\subsection{Input Storage: Targets and Target Input Files}
% ---------------------------------------------------------------------------- %
In many cases during this project, we wanted to work with \textit{only}
parameters that result in simulations that would have received a
Citizen Science score, and therefore elected to simply remove a significant
number of simulation parameters that resulted in a rejected simulation.

The input data files that contain the initial simulation
parameters are located in the \texttt{input} directory in the root directory
(\texttt{jspamcli.py} expects this to be their location).
These have been reduced in size from the
original files found at \texttt{https://data.galaxyzoo.org/mergers.html}, as
they now contain initial simulation parameters from scored runs. They are made
available in the GitHub repository.
% ---------------------------------------------------------------------------- %


% ---------------------------------------------------------------------------- %
%\subsection{JSPAM, Restricted three-body Simulations}\label{ssec: jspam}
% ---------------------------------------------------------------------------- %
%\todo[inline]{I was not able to add any review of restricted three-body
%    simulations as of yet. I will be adding more information here, as they are
%    essential for cutting down on computational time when the parameter space
%    is still too wide for any regular, beneficial, simulation of
%non-gravitational physics in full $n$-body simulations.}

%\todo[inline]{For some reason, I did not think to add a description of how the
%    actual simulation is run, as we did not write the simulation. Readers would
%    benefit from having this information included. I will be adding this in the
%future.}
% ---------------------------------------------------------------------------- %
% ---------------------------------------------------------------------------- %
\subsection{\texttt{merger} Python Package}
% ---------------------------------------------------------------------------- %
One of the primary challenges present in many projects in astronomy or
astrophysics is simply doing adequate book-keeping of data and related
information. This project is no different.
It was immediately necessary to develop a small,
purpose-built Python package to do just that. Within the \texttt{merger} package
found in the project repository, we make available the \texttt{MergerRun} and
\texttt{Galaxy} classes,
both of which are made available from the top level in the package. They can be
imported from the directory containing the merger package via
\say{\texttt{from merger import MergerRun, Galaxy}} or simply
\say{\texttt{from merger import .}}, although this second import statement also
imports a \texttt{data\_tools} package and \texttt{get\_target\_data} module which
will be described later.

Instantiation of a \texttt{MergerRun} is intended to require the fewest number
of arguments possible to reduce book-keeping. It does so by utilizing an
information file written by MergerEx during image preparation, which contains
a list of pertinent information. One of the member functions within the
\texttt{MergerRun} class simply turns this text file into a dict, which it then
initializes as several of the class instance attributes. An instance of this
class also requires the number of particles to be initialized in each disk, the
run number, and the initial simulation parameters that are found in the input
files. This can all be done in a statement such as

\begin{lstlisting}
merger_instance = MergerRun(path_to_info_file, n1_particles, n2_particles, run_number, init_sim_param_string)
\end{lstlisting}

Having a dedicated MergerRun class allows for \textit{all} of the necessary
information for a particular run of a merger to be passed between functions and
programs. While this method has potential to be a bit slower, we expect
programming using this class to remain a bit simpler and perhaps more clear.

This class also instantiates twice the \texttt{Galaxy} class,
one referred to as \texttt{primary} and the other referred to as
\texttt{secondary}. We can therefore more clearly keep track of the SDSS ID or
name, and regarding the disk centers, the right ascension and declination, and
the Cartesian coordinates relative to the pixels in the frame.

Within this package also a small package called \texttt{data\_tools} containing,
as of writing, one class called \texttt{Structure}. \texttt{Structure} accepts
an ordered list of directory and subdirectory names that will comprise a
directory structure to be created. In other words, the following code block

\begin{lstlisting}
dir_structure = Structure(["root_name", "child_1", "child_2", "child_3"])
\end{lstlisting}

will create the following path in your current working directory:
\texttt{root\_name/child\_1/child\_2/child\_3/}. Although this may seem
unneccessary, this reduces the chance of error in organization of the large
volume of simulation data that will be produced.

Further, in the top level of the package also exists \texttt{get\_target\_data}.
This is a module that specifically scrapes
\texttt{https://data.galaxyzoo.org/mergers.html} for all of the
available target data, allows for a user to select from the targets available,
downloads and unarchives the data into an \texttt{input} directory in the
working directory. This is more apparently useful in the interactive
mode of \texttt{jspamcli.py}.
% ---------------------------------------------------------------------------- %

% ---------------------------------------------------------------------------- %
\subsection{JSPAM Command Line Interface (\texttt{jspamcli.py})}
% ---------------------------------------------------------------------------- %
The original JSPAM code described in \citet{Wallin2016} can be called from
the command line via \texttt{./basic\_run} with a required string argument of
initial simulation parameters, and it accepts a number of options to specify
run settings and simulation quantities such as the number of particles to
be initialized around each center, for instance. While essentially all the
existing functionality has been fundamentally unchanged, we set out to make
interaction with the software more user friendly and intuitive.
Further, we wanted to
initiate the minimization of the human-in-the-loop even in the initial program
setup for new users.
After the Fortran90 code is compiled, users can run \texttt{jspamcli.py} using
Python3. This program can be run in four modes selected via command line
options. These modes are given as follows:
\begin{table}[h!]
    \centering
    \begin{tabular}{clll}
    \toprule
    Mode & Option       & Behavior                        & Arguments \\
    \midrule
    $1$ & \texttt{-i}  & run interactively               & NONE          \\
    $2$ & \texttt{-bi} & batch process interactively     & NONE          \\
    $3$ & \texttt{-b}  & batch process (normal)%
        & \texttt{batch\_run\_file}\ldots\\
    $4$ & \texttt{-bm} & batch process on multiple cores & \texttt{num\_cores}
    \texttt{batch\_run\_file}\ldots\\
    $5$ & \texttt{-g}  & GIF Creation Tool              & NONE          \\
    \bottomrule
    \end{tabular}
    \caption[\texttt{jspamcli.py} command line options]{List of command line options
        available in \texttt{jspamcli.py}. In the \texttt{-b} and \texttt{-bm}
    modes, multiple batch run files may be specified as long as they exist in
    the \texttt{batch\_run\_files} directory in the root directory.}
\end{table}
Mode $1$ allows interactive processing of multiple runs of one
target and can be called by \texttt{python3 jspamcli.py -i}.
Interaction with JSPAM is easy in this context, as all options are
handled interactively. The user is given an option to download input files using
the \texttt{get\_target\_data} module, and then can choose from available input
files to run the program. The user is then asked to enter the number of
particles to be initialized in each galaxy. Then, the program runs in
essentially the same way as in the batch processing modes.

Before \texttt{jspamcli.py} can be run in any of the batch processing modes
(modes $2-4$), one or more batch run files must be specified. If none are
specified, the program writes out a sample batch run file named
\texttt{sample.txt} in the \texttt{batch\_run\_file} directory.
The contents are below:
\begin{verbatim}
#target,n1_particles,n2_particles,first_run,last_run
587722984435351614,500,500,100,100
\end{verbatim}
However, if in the last column of a row there is the keyword \texttt{ALL}, the
values given for \texttt{first\_run} and \texttt{last\_run} are ignored
and all available non-rejected scored runs are processed. This file would read
\begin{verbatim}
#target,n1_particles,n2_particles,first_run,last_run
587722984435351614,500,500,000,000,ALL
\end{verbatim}

Modes $2-4$ are variations on batch processing modes and all make
use of the available batch run files.
Mode $2$ essentially gives the user an
introduction to how batch processing is handled by \texttt{jspamcli.py} and is
useful in contexts where the job to process does not have to be left running
for a exceedingly long duration of time.

Mode $3$ has all of the functionality of mode $2$ but none of the interactivity.
This mode runs as one would expect and processes all desired runs sequentially.

Mode $4$ contains methods for parallelizing the \texttt{basic\_run} process.
We wanted to minimize the need to change the original Fortran90 code, so the
Python \texttt{multiprocessing} module was used parallelize the execution of
the JSPAM simulation via \texttt{basic\_run} across multiple processors with
different arguments passed to the simulation in each.
While this does not necessarily reduce the time needed for any one simulation,
as JSPAM has not necessarily been parallelized itself,
this does reduce the amount of time
required to run a large number of simulations fairly quickly just by simply
doing more things at the same time. We can fairly easily significantly
speed up our workflow by making use of the cores available to us on any
workstation or machine.

Within the \texttt{multiprocessing} module is a \texttt{Pool} object that
accepts an argument indicating the number of worker processes to be spawned.
Upon execution of \texttt{jspamcli.py}, the argument passed to the program
indicating the requested number of cores to be used is used to instantiate the
\texttt{Pool} object (although we limit the number of cores to be used to half
of those available to preserve resources and good relations with other users).
Each execution of \texttt{basic\_run} using a
particular set of simulation parameters is considered to be completely
independent of all other processes, as the inputs for each simulation do not
depend on the results of the previous simulations. Therefore, we care very
little if all simulations requested run sequentially. We can therefore use the
\texttt{map\_async} module to distribute calls to the appropriate calling
function across the spawned worker processes.

Although we can now execute \texttt{basic\_run} processes across multiple cores,
we needed to take into account that this program writes out the initial and
final simulation data file. While the processes are not using a shared memory
location during the run, they are writing out these files to the same location.
The simple fix was to add an \texttt{-m} flag in \texttt{basic\_run} that
indicates that the program should insert a distinguishing number corresponding
to the process number in the name of the file. This allows for
\texttt{jspamcli.py} to organize the output files appropriately.
% ---------------------------------------------------------------------------- %


% ---------------------------------------------------------------------------- %
\subsection{Output Storage: Directory and File Naming Conventions}
% ---------------------------------------------------------------------------- %
We explored the possibility of adopting binary data
formats such as HDF5 rather than defaulting to flat files to store data.
While making use of binary data formats either by implementing an
IO interface that works across our existing programs in Fortran90, Python,
and C++ or by simply using HDF5 could potentially reduce IO overhead, it was
determined to not be an effective use of time at this point in the project.
Therefore, flat ASCII files are the working paradigm until another
solution is deemed necessary.

Because we are using flat files, we adopted a standard naming convention for all
output files regardless of their storage location. For any one particular run of
the JSPAM code, we identify a unique output file via the SDSSID or name used,
the run number corresponding to the line number in the input file, a flag
indicating whether the data corresponds to the initial output or the final
output, and the number of particles initialized in each galaxy. The output files
for a unique run would have the form

\begin{verbatim}
name.run_number.i.n1_particles.n2_particles.txt
name.run_number.f.n1_particles.n2_particles.txt
\end{verbatim}

Further, we needed to have an appropriate directory tree set up for any
particular run. We can visualize this tree in figure \ref{fig: the_tree}
\begin{figure}[h!]
    \dirtree{%
        .1 root.
        .2 output.
        .3 \{SDSSID\}.
        .4 \{SDSSID\}.humanscores.txt.
        .4 run0000.
        .5 \{SDSSID\}.0000.i.\{n1\_particles\}.\{n2\_particles\}.txt.
        .5 \{SDSSID\}.0000.f.\{n1\_particles\}.\{n2\_particles\}.txt.
        .4 run0001.
        .5 \{SDSSID\}.0001.i.\{n1\_particles\}.\{n2\_particles\}.txt.
        .5 \{SDSSID\}.0001.f.\{n1\_particles\}.\{n2\_particles\}.txt.
        .4 run0002.
        .5 \{SDSSID\}.0002.i.\{n1\_particles\}.\{n2\_particles\}.txt.
        .5 \{SDSSID\}.0002.f.\{n1\_particles\}.\{n2\_particles\}.txt.
        .4 run\ldots.
        .5 \{SDSSID\}.\{\ldots\}.i.\{n1\_particles\}.\{n2\_particles\}.txt.
        .5 \{SDSSID\}.\{\ldots\}.f.\{n1\_particles\}.\{n2\_particles\}.txt.
    }
    \caption[Output directory tree]{Output directory tree}
    \label{fig: the_tree}
\end{figure}


At this point \texttt{jspamcli.py} only needs minor additions to work with
the rendered image creation software and difference code which comprised the
other half of this project. Incorporating all pieces of the project in an
automated machine learning framework would require only a few augmentations,
to the existing code, and would support the ultimate goal of optimizing
the parameter space for better convergence on solutions.
This is likely to be explored in continuing research on this project.

% ---------------------------------------------------------------------------- %
% COMMENTED OUT
% ---------------------------------------------------------------------------- %
\begin{comment}
\subsection{Fitness-function Development}\label{ssec: fitness}
The primary goal of this work as a whole is to make progress on the
development of a fitness-function that will return some kind of machine score.
If we find an efficient method for determining convergence of models on the
observed morphologies that rivals that of a human fitness-function, we can then
begin using this method for real-time analysis of models. Although human
fitness-functions are robust and can make use of our innate pattern-matching
abilities \cite{Holincheck2015}, the ability to determine model convergence more
precisely with improved fitness-functions in
sequence with simulations immediately opens the door to improving the results
of previously applied genetic algorithms and applying new machine learning
techniques for optimizing the parameter space for all possible solutions.

That being said, we would be \textit{wrong} to not acknowledge the innate pattern-recognition abilities of humans that made the success of the Galaxy Zoo
project successful \cite{Holincheck2015}.
Rather than abandoning human interaction altogether once
a successful method for machine scoring is in place, perhaps a better approach
is to allow the machine scoring mechanism remove \say{bad} simulations from the
set that needs to receive a human score, effectively reducing the human choice
from the best of \textit{all} solutions to the best of \textit{good} solutions.

\todo[inline]{The current method of comparison is a simple normalization and
subtraction of translated images.}
\end{comment}
% ---------------------------------------------------------------------------- %
% COMMENTED OUT
% ---------------------------------------------------------------------------- %

% ---------------------------------------------------------------------------- %
%\subsection{Fitness-function Analysis}
% ---------------------------------------------------------------------------- %
%\todo[inline]{
%    This section currently has no information because no work has been done in
%    support of this section. Once we have several fitness functions working,
%    we will begin analyzing. I think since this is the primary goal of the
%    project, it really should live in the ANALYSIS section.
%}

%\subsection{Optimization of Initial Parameter Space}
%\todo[inline]{There will be more information added here in future when
%we arrive at this stage in the project, but I think that this will likely be
%better explored in continued research rather than the thesis.}


